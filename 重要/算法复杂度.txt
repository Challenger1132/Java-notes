/*
时间复杂度的定义：
	一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n)，
	使得当n趋近于无穷大时，T(n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。
	记作T(n)=O(f(n))，称O(f(n))为算法的渐进时间复杂度(O是数量级的符号)，简称时间复杂度。
	O运算代表对（）内进行求数量级运算，时间复杂度T(n)是辅助函数f(n)进行数量级运算之后的结果，T(n)=O(f(n))
	例如，T(n) = 2 + 4n + 3n*log2n，则T(n) = O(n*log2n)   --------------------->   "大O表示法"
	决定算法复杂度的是执行次数最多的语句，一般也是最内循环的语句---------------->执行次数最多的语句
	求T(n)的数量级，只要将T(n)进行如下一些操作：忽略常量、低次幂和最高次幂的系数，
并且一个算法花费的时间与算法中语句的执行次数成正比例,一个算法中的语句执行次数称为语句频度或时间频度,记为T(n)
n称为问题的规模，当n不断变化时，时间频度T(n)也会不断变化。
算法中语句执行次数为一个常数，则时间复杂度为O(1)
常见的时间复杂度有：常数阶O(1),对数阶O(log2n),线性阶O(n), 线性对数阶O(nlog2n),平方阶O(n2)，立方阶O(n3),...， 
k次方阶O(nk),指数阶O(2n)

一个算法在计算机存储器上所占用的存储空间，包括存储算法本身所占用的存储空间，
算法的输入输出数据所占用的存储空间和算法在运行过程中临时占用的存储空间这三个方面。
算法的时间复杂度与执行时间是两个完全不同的概念，算法的执行时间不随着问题规模n的增加而增长，
即使算法中有上千条语句，其执行时间也不过是一个较大的常数。此类算法的时间复杂度是O(1)


(1) int num1, num2;
(2) for(int i=0; i<n; i++){ 
(3)     num1 += 1;
(4)     for(int j=1; j<=n; j*=2){ 
(5)         num2 += num1;
(6)     }
(7) }
分析：
语句int num1, num2;的频度为1;
语句i=0;的频度为1;
语句i<n; i++; num1+=1; j=1; 的频度为n；
语句j<=n; j*=2; num2+=num1;的频度为n*log2n;  log2n是以2为底,n的对数
决定算法复杂度的是执行次数最多的语句,这里是num2 += num1,一般也是最内循环的语句

关于时间复杂度的运算规则：
1) 加法规则
T(n,m) = T1(n) + T2(n) = O (max ( f(n), g(m) )

2) 乘法规则
T(n,m) = T1(n) * T2(m) = O (f(n) * g(m))

3) 一个特例（问题规模为常量的时间复杂度）
在大O表示法里面有一个特例，如果T1(n) ＝ O(c),c是一个与n无关的任意常数,T2(n) = O ( f(n) ) 则有
T(n) = T1(n) * T2(n) = O ( c*f(n) ) = O( f(n) )
也就是说，在大O表示法中，任何非0正常数都属于同一数量级，记为O(1)。

4) 一个经验规则
复杂度与时间效率的关系：
c < log2n < n < n*log2n < n2 < n3 < 2n < 3n < n! （c是一个常量）
|--------------------------|--------------------------|-------------|
         较好                     一般              较差
其中c是一个常量，如果一个算法的复杂度为c 、 log2n 、n 、 n*log2n,那么这个算法时间效率比较高 
如果是 2n , 3n ,n!,那么稍微大一些的n就会令这个算法不能动了，居于中间的几个则差强人意。
*/
